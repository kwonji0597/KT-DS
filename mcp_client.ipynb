{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40bb1ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create server parameters for stdio connection\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your math_server.py file\n",
    "    args=[\"C:\\Users\\User\\kt-ds\\math_server.py\"], # math_server 서버경로\n",
    ")\n",
    "\n",
    "# 클라이언트는 비동기 방식으로 기동되어야 함\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # Create and run the agent\n",
    "        agent = create_react_agent(\"openai:gpt-4.1-mini\", tools) # 랭그래프에서 만드는 에이젼트 제공 (도구와 llm전달후 에이전트 )\n",
    "        agent_response = await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})  # 도구 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde29903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create server parameters for stdio connection\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"uvx\",\n",
    "    args=[\n",
    "        \"--from\",\n",
    "        \"mcpdoc\",\n",
    "        \"mcpdoc\",\n",
    "        \"--urls\",\n",
    "        \"LangGraph:https://langchain-ai.github.io/langgraph/llms.txt\",\n",
    "        \"--transport\",\n",
    "        \"stdio\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # Initialize the connection\n",
    "        await session.initialize()\n",
    "\n",
    "        # Get tools\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # Create and run the agent\n",
    "        agent = create_react_agent(\"openai:gpt-4.1-mini\", tools)\n",
    "        agent_response = await agent.ainvoke({\"messages\": \"Command 사용한 상태 관리에 대해서 알려주세요.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d45f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07852e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c145f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
